{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e9f7002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2061614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Código do Zscoore que fiz na lista 02, vou utilizar ele para normalizar os dados\n",
    "class Zscore():\n",
    "    def __init__(self, columnNumber = 2):\n",
    "        self.__means = np.empty(columnNumber)\n",
    "        self.__stds = np.empty(columnNumber)\n",
    "        self.__quantity = 0\n",
    "        \n",
    "    def __setMeans(self, newMeans):\n",
    "        self.__means = newMeans\n",
    "    \n",
    "    def getMeans(self):\n",
    "        return self.__means\n",
    "    \n",
    "    def __setStds(self, newStds):\n",
    "        self.__stds = newStds\n",
    "    \n",
    "    def getStds(self):\n",
    "        return self.__stds\n",
    "    \n",
    "    def __setQuantity(self, newQ):\n",
    "        self.__quantity = newQ\n",
    "    \n",
    "    def getQuantity(self):\n",
    "        return self.__quantity\n",
    "    \n",
    "    def __addValues(self, mu, sigma):\n",
    "        means = self.getMeans()\n",
    "        stds = self.getStds()\n",
    "        quantity = self.getQuantity()\n",
    "        \n",
    "        means[quantity] = mu\n",
    "        stds[quantity] = sigma\n",
    "        \n",
    "        self.__setMeans(means)\n",
    "        self.__setStds(stds)\n",
    "        \n",
    "        self.__setQuantity(quantity + 1)\n",
    "    \n",
    "    def scale(self, data):\n",
    "        rows = data.shape[0]\n",
    "        columns = data.shape[1]\n",
    "        #Utiliza a Normalização Z-score, seria o equivalente ao Standard Scaler\n",
    "        #Recebe um conjunto de dados e Retorna o mesmo conjunto de dados normalizado com média 0 e dp 1\n",
    "        dataScaled = np.empty([rows, 0])\n",
    "        for i in range(columns):\n",
    "            #Esse método faz a normalização coluna por coluna, onde i é o número da coluna\n",
    "            dataColumn = data[:, [i]]\n",
    "\n",
    "            #Cálculo da média e desvio-padrão da coluna que vai ser normalizada\n",
    "            mu = np.mean(dataColumn)\n",
    "            sigma = np.std(dataColumn)\n",
    "\n",
    "            columnScaled = (dataColumn - mu)/sigma\n",
    "            #columnScaled = (xi - mu)/sigma\n",
    "            #operação broadcasting para toda a coluna\n",
    "            dataScaled = np.c_[dataScaled, columnScaled]\n",
    "            \n",
    "            self.__addValues(mu, sigma)\n",
    "            #adiciona a coluna no dataset normalizado\n",
    "        #print(dataScaled)\n",
    "        return dataScaled\n",
    "    \n",
    "    def unscale(self, data, column = -1):\n",
    "        # pensando em implementar um atributo dataset original\n",
    "        # mas esse método tem como função principal fazer o \"unscale\" de novos atributos de um dado escalado\n",
    "        # anteriormente, como por exemplo ŷ que é escalado na normal com base nos dados de y\n",
    "        if column == -1:\n",
    "            mu = self.getMeans()\n",
    "            sigma = self.getStds()\n",
    "            \n",
    "        elif column >= self.getQuantity():\n",
    "            print(\"ERRO: Número de Coluna \", column ,\" Inválida.\")\n",
    "            return\n",
    "            \n",
    "        else:\n",
    "            mu = self.getMeans()[column]\n",
    "            sigma = self.getStds()[column]\n",
    "            \n",
    "        return sigma * data + mu\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45891e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbours():\n",
    "    def calculateDistance(self, point):\n",
    "\n",
    "        if self.distance == \"euclidiana\":\n",
    "            return np.apply_along_axis(lambda x: np.linalg.norm(x - point), axis=1, arr=self.X)\n",
    "        \n",
    "        elif self.distance == \"mahalanobis\": # aparentemente tá correto\n",
    "            x_diff = self.X - point\n",
    "            x_cov = np.linalg.inv(self.cov)\n",
    "            x_diff_cov = np.dot(x_diff, x_cov)\n",
    "            x_diff_cov_norm = np.sqrt(np.sum(x_diff_cov * x_diff, axis=1))\n",
    "            \n",
    "            return x_diff_cov_norm\n",
    "        else:\n",
    "            return -1\n",
    "        \n",
    "    def select_KNN(self, datapoint):\n",
    "        dists = self.calculateDistance(datapoint)\n",
    "        \n",
    "        distsIdx = np.argsort(dists)[:self.K]\n",
    "        unique, counts = np.unique(self.y[distsIdx], return_counts=True)\n",
    "        \n",
    "        idx = np.argsort(counts)[::-1]\n",
    "        \n",
    "        sorted_unique = unique[idx]\n",
    "        sorted_counts = counts[idx]\n",
    "        \n",
    "        return sorted_unique[0]\n",
    "\n",
    "    def train(self, X, y, K = 3,distance = \"euclidean\"):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.K = K\n",
    "        self.distance = distance\n",
    "        self.cov = np.array(np.cov(X.T))\n",
    "        self.cov = self.cov + 1e-10  * np.identity(self.cov.shape[0])\n",
    "        \n",
    "    def predict(self, X):\n",
    "        y_pred = np.apply_along_axis(self.select_KNN, 1, X) \n",
    "        # retorna uma matriz onde as linhas são os K menores distancias para cada valor em X,\n",
    "        # a matriz fica tamanho de linhas de X por K colunas\n",
    "        \n",
    "        # aparentemente Ok\n",
    "        return y_pred\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e367586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(X): # mesmo kfold que utilizei na lista 02\n",
    "    kfolds = []\n",
    "    n_splits = 10\n",
    "\n",
    "    # Embaralhar os índices dos dados\n",
    "    indices = np.random.permutation(len(X))\n",
    "\n",
    "    # Dividir os índices em n_splits partes iguais\n",
    "    folds_indices = np.array_split(indices, n_splits)\n",
    "\n",
    "    # Gerar KFold para cada conjunto de índices\n",
    "    for i in range(n_splits):\n",
    "        train_indices = np.concatenate(folds_indices[:i] + folds_indices[i+1:])\n",
    "        test_indices = folds_indices[i]\n",
    "        kfolds.append((train_indices, test_indices))\n",
    "    \n",
    "    return train_indices, test_indices, kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a65e5dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    # Accuracy Score: a proporção de acertos entre as previsões (y_pred) e os valores verdadeiros (y_true).\n",
    "\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def recall_score(y_true, y_pred):\n",
    "    # Recall Score: a proporção de verdadeiros positivos (TP) sobre o total de casos positivos (TP + FN).\n",
    "\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "def precision_score(y_true, y_pred):\n",
    "    # Precision Score: a proporção de verdadeiros positivos (TP) \n",
    "    # sobre o total de casos classificados como positivos (TP + FP).\n",
    "\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    # F1 Score: a média harmônica entre o Precision Score e o Recall Score.\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    return 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "326c4df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def questao1():\n",
    "    dataset = np.genfromtxt('.//ama_lista_03//kc2.csv', delimiter=',')\n",
    "    normalizer = Zscore(dataset.shape[1])\n",
    "    X = dataset[:, :21]\n",
    "    Y = dataset[:, 21]\n",
    "    X = normalizer.scale(X)\n",
    "    \n",
    "    train_indices, test_indices, kfolds = kfold(X)\n",
    "    \n",
    "    possibilidades = [(1, \"euclidiana\"), (5, \"euclidiana\"), (1, \"mahalanobis\"), (5, \"mahalanobis\")]\n",
    "    \n",
    "    for p in possibilidades:\n",
    "        K = p[0]\n",
    "        D = p[1]\n",
    "        \n",
    "        acc = np.zeros(10)\n",
    "        rcl = np.zeros(10)\n",
    "        prc = np.zeros(10)\n",
    "        f1  = np.zeros(10)\n",
    "    \n",
    "        for i, (train_indices, test_indices) in enumerate(kfolds): \n",
    "            KNN = KNearestNeighbours()\n",
    "\n",
    "            X_train = X[train_indices, :]\n",
    "            Y_train = Y[train_indices]\n",
    "\n",
    "            X_test = X[test_indices, :]\n",
    "            Y_test = Y[test_indices]\n",
    "            \n",
    "            KNN.train(X_train, Y_train, K, D)\n",
    "            \n",
    "            Y_hat = KNN.predict(X_test)\n",
    "            \n",
    "            acc[i] =(accuracy_score(Y_test, Y_hat))\n",
    "            rcl[i] =(recall_score(Y_test, Y_hat))\n",
    "            prc[i] =(precision_score(Y_test, Y_hat))\n",
    "            f1[i]  =(f1_score(Y_test, Y_hat))\n",
    "        \n",
    "        \n",
    "        print(\"Métricas do KNN para K =\", K, \" e Distância do tipo\", D)\n",
    "        print(\"            Médias            Desvio-Padrão\")\n",
    "            \n",
    "        print(\"Acurácia:  \", f\"{acc.mean():.15f}\", f\"{acc.std():.15f}\")\n",
    "        print(\"Revocação: \", f\"{rcl.mean():.15f}\", f\"{rcl.std():.15f}\")\n",
    "        print(\"Precisão:  \", f\"{prc.mean():.15f}\", f\"{prc.std():.15f}\")\n",
    "        print(\"F1-Score:  \", f\"{f1.mean():.15f}\", f\"{f1.std():.15f}\")\n",
    "            \n",
    "        print(\"_\"*60)\n",
    "        print()\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8cedbdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def questao2():\n",
    "    dataset = np.genfromtxt('.//ama_lista_03//kc2.csv', delimiter=',')\n",
    "    normalizer = Zscore(dataset.shape[1])\n",
    "    X = dataset[:, :21]\n",
    "    Y = dataset[:, 21]\n",
    "    X = normalizer.scale(X)\n",
    "    \n",
    "    train_indices, test_indices, kfolds = kfold(X)\n",
    "    \n",
    "    possibilidades = [\"gini\", \"entropy\"]\n",
    "    \n",
    "    for p in possibilidades:\n",
    "        tipo = p\n",
    "        \n",
    "        acc = np.zeros(10)\n",
    "        rcl = np.zeros(10)\n",
    "        prc = np.zeros(10)\n",
    "        f1  = np.zeros(10)\n",
    "    \n",
    "        for i, (train_indices, test_indices) in enumerate(kfolds): \n",
    "            DTC = DecisionTreeClassifier(random_state = 42, criterion = p)\n",
    "\n",
    "            X_train = X[train_indices, :]\n",
    "            Y_train = Y[train_indices]\n",
    "\n",
    "            X_test = X[test_indices, :]\n",
    "            Y_test = Y[test_indices]\n",
    "            \n",
    "            DTC.fit(X_train, Y_train)\n",
    "            \n",
    "            Y_hat = DTC.predict(X_test)\n",
    "            \n",
    "            acc[i] =(accuracy_score(Y_test, Y_hat))\n",
    "            rcl[i] =(recall_score(Y_test, Y_hat))\n",
    "            prc[i] =(precision_score(Y_test, Y_hat))\n",
    "            f1[i]  =(f1_score(Y_test, Y_hat))\n",
    "        \n",
    "        \n",
    "        print(\"Métricas da Árvore de Decisão construída a partir de\", p)\n",
    "        print(\"            Médias            Desvio-Padrão\")\n",
    "            \n",
    "        print(\"Acurácia:  \", f\"{acc.mean():.15f}\", f\"{acc.std():.15f}\")\n",
    "        print(\"Revocação: \", f\"{rcl.mean():.15f}\", f\"{rcl.std():.15f}\")\n",
    "        print(\"Precisão:  \", f\"{prc.mean():.15f}\", f\"{prc.std():.15f}\")\n",
    "        print(\"F1-Score:  \", f\"{f1.mean():.15f}\", f\"{f1.std():.15f}\")\n",
    "            \n",
    "        print(\"_\"*60)\n",
    "        print()\n",
    "    \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5dba2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas do KNN para K = 1  e Distância do tipo euclidiana\n",
      "            Médias            Desvio-Padrão\n",
      "Acurácia:   0.701298701298701 0.102383469212999\n",
      "Revocação:  0.743769286269286 0.128373656399441\n",
      "Precisão:   0.706053946053946 0.154880534451931\n",
      "F1-Score:   0.706863194717503 0.094910405370978\n",
      "____________________________________________________________\n",
      "\n",
      "Métricas do KNN para K = 5  e Distância do tipo euclidiana\n",
      "            Médias            Desvio-Padrão\n",
      "Acurácia:   0.765800865800866 0.082642041900278\n",
      "Revocação:  0.748468059718060 0.141996428058255\n",
      "Precisão:   0.767777777777778 0.154930674077732\n",
      "F1-Score:   0.746316581180465 0.120841949615926\n",
      "____________________________________________________________\n",
      "\n",
      "Métricas do KNN para K = 1  e Distância do tipo mahalanobis\n",
      "            Médias            Desvio-Padrão\n",
      "Acurácia:   0.654545454545455 0.095337413777834\n",
      "Revocação:  0.697095404595405 0.173781190730885\n",
      "Precisão:   0.687350288600289 0.157055555497966\n",
      "F1-Score:   0.659048333277774 0.083993890776681\n",
      "____________________________________________________________\n",
      "\n",
      "Métricas do KNN para K = 5  e Distância do tipo mahalanobis\n",
      "            Médias            Desvio-Padrão\n",
      "Acurácia:   0.733549783549784 0.059059186258312\n",
      "Revocação:  0.690245032745033 0.124534903637378\n",
      "Precisão:   0.766201298701299 0.148224027629497\n",
      "F1-Score:   0.710414023540959 0.088489176295973\n",
      "____________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questao1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f13d272a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas da Árvore de Decisão construída a partir de gini\n",
      "            Médias            Desvio-Padrão\n",
      "Acurácia:   0.720129870129870 0.088273748322500\n",
      "Revocação:  0.724152514152514 0.171003757524622\n",
      "Precisão:   0.735444000444000 0.093469831314468\n",
      "F1-Score:   0.712331102563301 0.090346912732777\n",
      "____________________________________________________________\n",
      "\n",
      "Métricas da Árvore de Decisão construída a partir de entropy\n",
      "            Médias            Desvio-Padrão\n",
      "Acurácia:   0.682251082251082 0.097694607974818\n",
      "Revocação:  0.658559773559774 0.147150209360020\n",
      "Precisão:   0.713066100566101 0.121779904014021\n",
      "F1-Score:   0.665868574150308 0.099017506714478\n",
      "____________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questao2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
